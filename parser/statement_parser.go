package parser

import (
	"fmt"
	"log"
	"model_infrax/config"
	"model_infrax/model"
	"os"
	"strings"

	"github.com/pingcap/tidb/pkg/parser"
	"github.com/pingcap/tidb/pkg/parser/ast"
	"github.com/pingcap/tidb/pkg/parser/test_driver"
	"github.com/samber/lo"
)

type StatementParser struct {
	configger  *config.Configger
	statements []string
}

// NewStatementParser åˆ›å»ºSQLè¯­å¥è§£æå™¨
// ä»é…ç½®æ–‡ä»¶ä¸­è¯»å–SQLæ–‡ä»¶è·¯å¾„ï¼Œè§£æSQLæ–‡ä»¶å†…å®¹
func NewStatementParser(cfg *config.Configger) (*StatementParser, error) {
	// ä»é…ç½®ä¸­è·å–SQLæ–‡ä»¶è·¯å¾„
	sqlFilePath := cfg.GenerateConfig.SqlFilePath
	if sqlFilePath == "" {
		return nil, fmt.Errorf("statementæ¨¡å¼ä¸‹å¿…é¡»é…ç½®sql_file_path")
	}

	// è¯»å–SQLæ–‡ä»¶å†…å®¹
	byts, err := os.ReadFile(sqlFilePath)
	if err != nil {
		return nil, fmt.Errorf("è¯»å–SQLæ–‡ä»¶å¤±è´¥ [%s]: %w", sqlFilePath, err)
	}

	// æŒ‰åˆ†å·åˆ†å‰²SQLè¯­å¥
	statements := strings.Split(string(byts), ";")

	log.Printf("ğŸ“„ æˆåŠŸåŠ è½½SQLæ–‡ä»¶: %s, å…± %d æ¡è¯­å¥", sqlFilePath, len(statements))

	return &StatementParser{
		configger:  cfg,
		statements: statements,
	}, nil
}

func (p *StatementParser) Parse() (schemas []model.Schema, err error) {
	for _, statement := range p.statements {
		// è·³è¿‡ç©ºè¯­å¥
		trimmed := strings.TrimSpace(statement)
		if trimmed == "" {
			continue
		}

		log.Printf("âŒ›ï¸ parsing statement: %s", statement)
		var schema model.Schema
		schema, err = p.parseStatement(statement)
		if err != nil {
			return nil, fmt.Errorf("è§£æè¯­å¥å¤±è´¥: %w", err)
		}
		schemas = append(schemas, schema)
	}
	return
}

func (p *StatementParser) FilterTables(schemas []model.Schema) (filtered []model.Schema) {
	if p.configger.GenerateConfig.AllTables {
		filtered = schemas
		return
	}
	filtered = lo.Filter(schemas, func(schema model.Schema, index int) bool {
		return lo.Contains(p.configger.GenerateConfig.TableNames, schema.Name)
	})
	return
}

// parseStatement è§£æå•ä¸ªCREATE TABLEè¯­å¥ï¼Œæå–è¡¨ç»“æ„ä¿¡æ¯
func (p *StatementParser) parseStatement(statement string) (schema model.Schema, err error) {
	// åˆ›å»ºTiDB parserå®ä¾‹
	tidbParser := parser.New()

	// è§£æSQLè¯­å¥
	stmtNodes, _, err := tidbParser.ParseSQL(statement)
	if err != nil {
		return schema, fmt.Errorf("SQLè§£æå¤±è´¥: %w", err)
	}

	// ç¡®ä¿è‡³å°‘æœ‰ä¸€ä¸ªè¯­å¥èŠ‚ç‚¹
	if len(stmtNodes) == 0 {
		return schema, fmt.Errorf("æœªæ‰¾åˆ°æœ‰æ•ˆçš„SQLè¯­å¥")
	}

	// è·å–ç¬¬ä¸€ä¸ªè¯­å¥èŠ‚ç‚¹
	stmtNode := stmtNodes[0]

	// ç±»å‹æ–­è¨€ä¸ºCREATE TABLEè¯­å¥
	createTableStmt, ok := stmtNode.(*ast.CreateTableStmt)
	if !ok {
		return schema, fmt.Errorf("ä¸æ˜¯CREATE TABLEè¯­å¥")
	}

	// æå–è¡¨å
	schema.Name = createTableStmt.Table.Name.O

	// æå–è¡¨æ³¨é‡Š
	for _, option := range createTableStmt.Options {
		if option.Tp == ast.TableOptionComment {
			schema.Comment = option.StrValue
			break
		}
	}

	// ç”¨äºå­˜å‚¨åˆ—ååˆ°åˆ—çš„æ˜ å°„ï¼Œæ–¹ä¾¿åç»­ç´¢å¼•å¤„ç†
	columnMap := make(map[string]*model.Column)

	// æå–åˆ—ä¿¡æ¯
	for _, col := range createTableStmt.Cols {
		column := model.Column{
			ColumnName: col.Name.Name.O,
			Type:       col.Tp.String(),
		}

		// æå–åˆ—çš„å„ç§å±æ€§
		for _, option := range col.Options {
			switch option.Tp {
			case ast.ColumnOptionComment:
				// æå–åˆ—æ³¨é‡Šï¼šä»ValueExprçš„Datum.bå­—æ®µä¸­è¯»å–UTF-8ç¼–ç çš„å­—èŠ‚æ•°ç»„
				if option.Expr != nil {
					// å°è¯•ç±»å‹æ–­è¨€ä¸ºtest_driver.ValueExpr
					if valueExpr, ok := option.Expr.(*test_driver.ValueExpr); ok {
						// Datum.b å­˜å‚¨çš„æ˜¯UTF-8ç¼–ç çš„å­—èŠ‚æ•°ç»„
						if len(valueExpr.Datum.GetBytes()) > 0 {
							column.Comment = string(valueExpr.Datum.GetBytes())
						}
					}
				}
				// å¦‚æœExpræ–¹å¼æ²¡å–åˆ°ï¼Œå°è¯•StrValueï¼ˆå…¼å®¹å¤„ç†ï¼‰
				if column.Comment == "" && option.StrValue != "" {
					column.Comment = option.StrValue
				}
			case ast.ColumnOptionDefaultValue:
				// æå–é»˜è®¤å€¼ï¼šéœ€è¦åŒºåˆ†ValueExprï¼ˆå­—ç¬¦ä¸²/æ•°å€¼ï¼‰å’ŒFuncCallExprï¼ˆå‡½æ•°å¦‚CURRENT_TIMESTAMPï¼‰
				if option.Expr != nil {
					var defaultVal string

					// å¤„ç†ValueExprç±»å‹ï¼ˆå­—ç¬¦ä¸²æˆ–æ•°å€¼é»˜è®¤å€¼ï¼‰
					if valueExpr, ok := option.Expr.(*test_driver.ValueExpr); ok {
						// å¦‚æœDatum.bä¸ºç©ºå­—èŠ‚æ•°ç»„ï¼Œè¡¨ç¤ºç©ºå­—ç¬¦ä¸²''
						if len(valueExpr.Datum.GetBytes()) == 0 {
							defaultVal = ""
						} else {
							// å¦åˆ™è½¬æ¢å­—èŠ‚æ•°ç»„ä¸ºå­—ç¬¦ä¸²
							defaultVal = string(valueExpr.Datum.GetBytes())
						}
					} else if funcExpr, ok := option.Expr.(*ast.FuncCallExpr); ok {
						// å¤„ç†FuncCallExprç±»å‹ï¼ˆå¦‚CURRENT_TIMESTAMPï¼‰
						defaultVal = funcExpr.FnName.O
					}

					column.Default = &defaultVal
				}
			case ast.ColumnOptionAutoIncrement:
				// æ ‡è®°è‡ªå¢åˆ—
				column.IsAutoIncrement = true
			case ast.ColumnOptionNull:
				// æ ‡è®°å…è®¸NULL
				column.IsNullable = true
			case ast.ColumnOptionNotNull:
				// æ ‡è®°ä¸å…è®¸NULL
				column.IsNullable = false
			case ast.ColumnOptionPrimaryKey:
				// æ ‡è®°ä¸»é”®
				column.IsPrimaryKey = true
			case ast.ColumnOptionUniqKey:
				// æ ‡è®°å”¯ä¸€é”®
				column.IsUnique = true
			}
		}

		// æå–å­—ç¬¦é›†æ ¡å¯¹è§„åˆ™
		if col.Tp.GetCollate() != "" {
			column.Collate = col.Tp.GetCollate()
		}

		schema.Columns = append(schema.Columns, column)
		columnMap[column.ColumnName] = &schema.Columns[len(schema.Columns)-1]
	}
	for _, constraint := range createTableStmt.Constraints {
		switch constraint.Tp {
		case ast.ConstraintPrimaryKey:
			// å¤„ç†ä¸»é”®
			var pkColumns []model.Column
			for _, indexCol := range constraint.Keys {
				colName := indexCol.Column.Name.O
				if col, exists := columnMap[colName]; exists {
					col.IsPrimaryKey = true
					col.IsIndexed = true
					pkColumns = append(pkColumns, *col)
				}
			}
			schema.PrimaryKey = model.Index{
				IndexName: "PRIMARY",
				Columns:   pkColumns,
			}

		case ast.ConstraintUniq, ast.ConstraintUniqKey, ast.ConstraintUniqIndex:
			// å¤„ç†å”¯ä¸€ç´¢å¼•
			var uniqueColumns []model.Column
			for _, indexCol := range constraint.Keys {
				colName := indexCol.Column.Name.O
				if col, exists := columnMap[colName]; exists {
					col.IsUnique = true
					col.IsIndexed = true
					uniqueColumns = append(uniqueColumns, *col)
				}
			}
			indexName := constraint.Name
			if indexName == "" {
				// å¦‚æœæ²¡æœ‰æŒ‡å®šç´¢å¼•åï¼Œä½¿ç”¨åˆ—åç»„åˆ
				indexName = "uk_" + strings.Join(lo.Map(uniqueColumns, func(c model.Column, _ int) string {
					return c.ColumnName
				}), "_")
			}
			schema.UniqueIndex = append(schema.UniqueIndex, model.Index{
				IndexName: indexName,
				Columns:   uniqueColumns,
			})

		case ast.ConstraintKey, ast.ConstraintIndex:
			// å¤„ç†æ™®é€šç´¢å¼•
			var indexColumns []model.Column
			for _, indexCol := range constraint.Keys {
				colName := indexCol.Column.Name.O
				if col, exists := columnMap[colName]; exists {
					col.IsIndexed = true
					indexColumns = append(indexColumns, *col)
				}
			}
			indexName := constraint.Name
			if indexName == "" {
				// å¦‚æœæ²¡æœ‰æŒ‡å®šç´¢å¼•åï¼Œä½¿ç”¨åˆ—åç»„åˆ
				indexName = "idx_" + strings.Join(lo.Map(indexColumns, func(c model.Column, _ int) string {
					return c.ColumnName
				}), "_")
			}
			schema.Indexes = append(schema.Indexes, model.Index{
				IndexName: indexName,
				Columns:   indexColumns,
			})
		default:

		}
	}

	log.Printf("âœ… æˆåŠŸè§£æè¡¨: %s, åˆ—æ•°: %d, ç´¢å¼•æ•°: %d", schema.Name, len(schema.Columns), len(schema.Indexes))
	return schema, nil
}
